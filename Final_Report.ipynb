{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee0ea66e",
   "metadata": {},
   "source": [
    "# Zillow Data Final Report   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d2b5c9",
   "metadata": {},
   "source": [
    "# Zachary Stufflebeme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23552d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grab_db import my_db\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from zillow_wrangle import my_train_test_split, clean_zillow, plot_variable_pairs, plot_categorical_and_continuous_vars, get_zillow_data, scale_zillow\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from evaluate import plot_residuals, regression_errors, baseline_mean_errors, better_than_baseline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression, LassoLars, TweedieRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b5edbf",
   "metadata": {},
   "source": [
    "# My Plan:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2dd7d2b",
   "metadata": {},
   "source": [
    "Aquire: acquire data through functions saved in my acquire.py along with my encrypted credentials.\n",
    "\n",
    "Prepare: Prepare and clean my data in such a way that I can plug it in to my Regression models without causing error and with the prepared data still holding true to its original meaning.\n",
    "\n",
    "Explore: Ask statistical questions of my data and create visualizations of the results in order to improve comprehension by people reading the report without clarifications from my presentation.\n",
    "\n",
    "Model:Create models and adjust parameters to try to closely predict house prices, Validate that all of your models are accurate not just on your train data but on outside data as well.\n",
    "\n",
    "Deliver: Put all of my findings together in a final report where I make things as easy to understand as possible.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e0a83c",
   "metadata": {},
   "source": [
    "# Project Summary:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf5fb3d",
   "metadata": {},
   "source": [
    ".In my project I was able to create 3 models That all performed similarly well and above the baseline I used bedroomcnt, bathroomcnt, calculatedfinishedsquarefeet, poolcnt, and age. My polynomial model was my best model as it had the lowest RMSE on train and validate. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c6fff7",
   "metadata": {},
   "source": [
    "# Acquire Data:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fa015d0",
   "metadata": {},
   "source": [
    "Most of the work here has already been taken care of in my acquire.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "efdd24c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow = get_zillow_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "acb50a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>taxvaluedollarcnt</th>\n",
       "      <th>fips</th>\n",
       "      <th>yearbuilt</th>\n",
       "      <th>bedroomcnt</th>\n",
       "      <th>bathroomcnt</th>\n",
       "      <th>calculatedfinishedsquarefeet</th>\n",
       "      <th>garagecarcnt</th>\n",
       "      <th>lotsizesquarefeet</th>\n",
       "      <th>poolcnt</th>\n",
       "      <th>regionidzip</th>\n",
       "      <th>roomcnt</th>\n",
       "      <th>numberofstories</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1023282.0</td>\n",
       "      <td>6059.0</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4506.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>96978.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>464000.0</td>\n",
       "      <td>6111.0</td>\n",
       "      <td>1967.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1465.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12647.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>97099.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>564778.0</td>\n",
       "      <td>6059.0</td>\n",
       "      <td>1962.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1243.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8432.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>97078.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>145143.0</td>\n",
       "      <td>6037.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2376.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13038.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96330.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>773303.0</td>\n",
       "      <td>6037.0</td>\n",
       "      <td>1950.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2962.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>96293.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   taxvaluedollarcnt    fips  yearbuilt  bedroomcnt  bathroomcnt  \\\n",
       "0          1023282.0  6059.0     1998.0         4.0          3.5   \n",
       "1           464000.0  6111.0     1967.0         2.0          1.0   \n",
       "2           564778.0  6059.0     1962.0         3.0          2.0   \n",
       "3           145143.0  6037.0     1970.0         4.0          3.0   \n",
       "4           773303.0  6037.0     1950.0         4.0          3.0   \n",
       "\n",
       "   calculatedfinishedsquarefeet  garagecarcnt  lotsizesquarefeet  poolcnt  \\\n",
       "0                        3100.0           2.0             4506.0      NaN   \n",
       "1                        1465.0           1.0            12647.0      NaN   \n",
       "2                        1243.0           2.0             8432.0      1.0   \n",
       "3                        2376.0           NaN            13038.0      1.0   \n",
       "4                        2962.0           NaN            63000.0      1.0   \n",
       "\n",
       "   regionidzip  roomcnt  numberofstories  \n",
       "0      96978.0      0.0              NaN  \n",
       "1      97099.0      5.0              1.0  \n",
       "2      97078.0      6.0              1.0  \n",
       "3      96330.0      0.0              NaN  \n",
       "4      96293.0      0.0              NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zillow.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8499403",
   "metadata": {},
   "source": [
    "This is the way the dataframe is formatted before I make any changes. I retrieved the data from our SQL database using my encrypted credentials from my env file. The data is not formatted very well for me to use our regression models and I will have to make a lot of changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78eca70b",
   "metadata": {},
   "source": [
    "# Prepare Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "820a260c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here I am running the previous df through my prepare functions i created in my prepare.py\n",
    "zillow = clean_zillow(zillow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d54f3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is calling the dataframe I've just run through prepare\n",
    "#This is how I have chosen to get rid of outliers that ruin the score of my model.\n",
    "#I have cut out houses that are above the price of 2 million dollars.\n",
    "zillow = zillow[zillow['taxvaluedollarcnt'] < 2000000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec94d2bc",
   "metadata": {},
   "source": [
    "As you can see I have made a lot of changes to the data within my prepare.py in order for it to be formatted in a way that works with the different ML models I will be creating."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb0e4e1",
   "metadata": {},
   "source": [
    "Preperation is where I found myself spending most of my time as the Zillow data was not perfect for model creation. I will try and briefly summarize what I did: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a33f538",
   "metadata": {},
   "source": [
    "- deleted all columns filled with duplicate values to get rid of unnecessary features.\n",
    "- tried to impute different missing values using logic where possible.\n",
    "- create a function to scale all values other than my target between 0 and 1 to better fit my data\n",
    "- made new encoded columns of my categorical variables to use them in my models.\n",
    "- drop all of the old columns I just encoded \n",
    "-  fix muddy data such as nulls that were appearing in certain places which was linked to weather or not they had structures built on the property or not"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6b5d48",
   "metadata": {},
   "source": [
    "# Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d6b04fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calling my split data function from my prepare in order to have training, validating, and testing portions of my data.\n",
    "train, validate, test = my_train_test_split(zillow)\n",
    "train, validate, test = my_train_test_split(zillow)\n",
    "x_train = train.drop(columns = 'taxvaluedollarcnt')\n",
    "y_train = train.taxvaluedollarcnt\n",
    "x_validate = validate.drop(columns = 'taxvaluedollarcnt')\n",
    "y_validate = validate.taxvaluedollarcnt\n",
    "y_train = pd.DataFrame(y_train)\n",
    "y_validate = pd.DataFrame(y_validate)\n",
    "x_test = test.drop(columns = 'taxvaluedollarcnt')\n",
    "y_test = test.taxvaluedollarcnt\n",
    "y_test = pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a6145ab",
   "metadata": {},
   "source": [
    "# Data Exploration:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cbd33f5-086c-44f8-a60d-6fdfc46b45e0",
   "metadata": {},
   "source": [
    "alpha = .05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82700660",
   "metadata": {},
   "source": [
    "QUESTION 1: Is bedroom count correlated to house price?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c30f7c5",
   "metadata": {},
   "source": [
    "- Hnull - bedroomcnt is not correlated with taxvaluedollarcnt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b875bcd",
   "metadata": {},
   "source": [
    "- Halt - bedroomcnt is correlated with taxvaluedollarcnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2075af48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here I am creating the visualization you see below\n",
    "plt.bar(train.bedroomcnt,train.taxvaluedollarcnt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "673dcfc8-72ed-4fca-8273-d32f0a6c1363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.2721934759424902, 0.0)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here I am running a correlation test on bedroom count and house price.\n",
    "corr, p = pearsonr(train.bedroomcnt, train.taxvaluedollarcnt)\n",
    "corr, p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19a45134",
   "metadata": {},
   "source": [
    "Since my p-val is less than .05 I can reject the null hypothesis that there is no correlation between bedroom count and house price. The .27 as my corr value indicates that the correlation is positive but weak. However it still could be a useful feature for my model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391f763d",
   "metadata": {},
   "source": [
    "QUESTION 2: Is bathroom count correlated to house price?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c0727b",
   "metadata": {},
   "source": [
    "- Hnull - bathroom count is not correlated to house price.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a39487",
   "metadata": {},
   "source": [
    "- Halt - bathroom count is correlated to house price\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "110ead28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#here I am creating the visualization you see below\n",
    "plt.bar(train.bathroomcnt,train.taxvaluedollarcnt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e99b75fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5038944777939824, 0.0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here I am running a correlation test on bathroom count and house price.\n",
    "corr, p = pearsonr(train.bathroomcnt, train.taxvaluedollarcnt)\n",
    "corr, p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "931fe725",
   "metadata": {},
   "source": [
    "Since the p-val is less than alpha we can reject the null hypothesis that bathroom count is not correlated to house price. Since my correlation value is around .5 the correlation is positive and moderate in strength."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d6acbe",
   "metadata": {},
   "source": [
    "This means that Using bathroom count could be useful for our modeling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf4f85c",
   "metadata": {},
   "source": [
    "QUESTION 3: Is square feet correlated with house price?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed5cbc6",
   "metadata": {},
   "source": [
    "- Hnull - square feet is not correlated with house price."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9fe527",
   "metadata": {},
   "source": [
    "- Halt - square feet is correlated with house price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95f1f0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here I am creating the visualization you see below\n",
    "plt.scatter(train.calculatedfinishedsquarefeet,train.taxvaluedollarcnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad232b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5756816296036781, 0.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here I am running a correlation test on square feet and house price.\n",
    "corr, p = pearsonr(train.calculatedfinishedsquarefeet, train.taxvaluedollarcnt)\n",
    "corr, p\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1bbaf7",
   "metadata": {},
   "source": [
    "Since the p-val is less than alpha we can reject the null hypothesis and can conclude that square feet and house price are positivelhy correlated with moderate strength. This mens square feet could be a useful feature for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce98ddfe",
   "metadata": {},
   "source": [
    "Question 4: is house age correlated to house price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fa05de36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here is the code for the visual below\n",
    "plt.scatter(train.age,train.taxvaluedollarcnt)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ead89689-5e37-400c-9f52-322d35802e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.25099832014569856, 0.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Here is a correlation test on house age and house price\n",
    "corr, p = pearsonr(train.age,train.taxvaluedollarcnt)\n",
    "corr, p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ee422c",
   "metadata": {},
   "source": [
    "since my p is less than alpha I can reject the null hypothesis. This means there is a correlation between age and house price that is negativ and somewhat weak in strength. However this correlation could still prove useful for my model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2055a14",
   "metadata": {},
   "source": [
    "IMPORTANT FINDINGS FROM EXPLORATION:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d326f23",
   "metadata": {},
   "source": [
    "- Bedroom count is positively correlated to my target and is useful for modeling\n",
    "- Bathroom count is positively correlated to my target and is useful for modeling\n",
    "- Square feet is positively correlated to my target and is useful for modeling\n",
    "- house age is negatively correlated to my targer and is useful for modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbc78c7",
   "metadata": {},
   "source": [
    "# Models and Evaluation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393aa8f2",
   "metadata": {},
   "source": [
    "Models I will make:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0261433",
   "metadata": {},
   "source": [
    "- LassoLars"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78e8d52",
   "metadata": {},
   "source": [
    "- TweedieRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8d0c54",
   "metadata": {},
   "source": [
    "- Polynomial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3c4719",
   "metadata": {},
   "source": [
    "I found the most success using bedroomcnt, bathroomcnt, square feet, poolcnt, and house age."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cbfcad-d16f-468a-a6f2-50fab9bb7a3a",
   "metadata": {},
   "source": [
    "RMSE using Mean\n",
    "Train/In-Sample:  352200.76 \n",
    "Validate/Out-of-Sample:  358833.99"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2394ba",
   "metadata": {},
   "source": [
    "-------------------------------------------------------------Lasso/Lars---------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "64757727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Lasso + Lars\n",
      "Training/In-Sample:  281339.4570491243 \n",
      "Validation/Out-of-Sample:  288485.4203244481\n"
     ]
    }
   ],
   "source": [
    "#This is where I create my Lasso Lars model\n",
    "# create the model object\n",
    "lars = LassoLars(alpha=1.0)\n",
    "\n",
    "# fit the model \n",
    "\n",
    "lars.fit(x_train, y_train.taxvaluedollarcnt)\n",
    "\n",
    "# predict train\n",
    "y_train['taxval_pred_lars'] = lars.predict(x_train)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train = mean_squared_error(y_train.taxvaluedollarcnt, y_train.taxval_pred_lars)**(1/2)\n",
    "\n",
    "# predict validate\n",
    "y_validate['taxval_pred_lars'] = lars.predict(x_validate)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_validate = mean_squared_error(y_validate.taxvaluedollarcnt, y_validate.taxval_pred_lars)**(1/2)\n",
    "\n",
    "print(\"RMSE for Lasso + Lars\\nTraining/In-Sample: \", rmse_train,\n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc1597f",
   "metadata": {},
   "source": [
    "As you can see we have already validated above the baseline! This is great news but lets keep digging into other models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67b3348",
   "metadata": {},
   "source": [
    "------------------------------------------------------------TweedieRegressor------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15f0511e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for GLM using Tweedie, power=1 & alpha=0\n",
      "Training/In-Sample:  294630.9767196031 \n",
      "Validation/Out-of-Sample:  329772.1033439407\n"
     ]
    }
   ],
   "source": [
    "# create the model object\n",
    "glm = TweedieRegressor(power=1, alpha=0)\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train,\n",
    "# since we have converted it to a dataframe from a series!\n",
    "glm.fit(x_train, y_train.taxvaluedollarcnt)\n",
    "\n",
    "# predict train\n",
    "y_train['taxval_pred_glm'] = glm.predict(x_train)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train = mean_squared_error(y_train.taxvaluedollarcnt, y_train.taxval_pred_glm)**(1/2)\n",
    "\n",
    "# predict validate\n",
    "y_validate['taxval_pred_glm'] = glm.predict(x_validate)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_validate = mean_squared_error(y_validate.taxvaluedollarcnt, y_validate.taxval_pred_glm)**(1/2)\n",
    "\n",
    "print(\"RMSE for GLM using Tweedie, power=1 & alpha=0\\nTraining/In-Sample: \", rmse_train,\n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16701666",
   "metadata": {},
   "source": [
    "above is how we score on validate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb34389",
   "metadata": {},
   "source": [
    "Here I am scoring an RMSE extremely similar to the baseline therefor this model wont be  very useful going forward as it has already performed worse than my first model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074c6517",
   "metadata": {},
   "source": [
    "------------------------------------------------------------Polynomial------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "50b78c61-90bf-4a23-b232-578f06fdbb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the polynomial features to get a new set of features\n",
    "pf = PolynomialFeatures(degree=2)\n",
    "\n",
    "# fit and transform X_train_scaled\n",
    "x_train_degree2 = pf.fit_transform(x_train)\n",
    "\n",
    "# transform X_validate_scaled & X_test_scaled\n",
    "x_validate_degree2 = pf.transform(x_validate)\n",
    "x_test_degree2 = pf.transform(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a94e464f-8e26-475c-b62d-eb243843a145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Polynomial Model, degrees=2\n",
      "Training/In-Sample:  275775.101445778 \n",
      "Validation/Out-of-Sample:  281584.4785686004\n"
     ]
    }
   ],
   "source": [
    "# create the model object\n",
    "lm2 = LinearRegression(normalize=True)\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train,\n",
    "# since we have converted it to a dataframe from a series!\n",
    "lm2.fit(x_train_degree2, y_train.taxvaluedollarcnt)\n",
    "\n",
    "# predict train\n",
    "y_train['taxval_pred_lm2'] = lm2.predict(x_train_degree2)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_train = mean_squared_error(y_train.taxvaluedollarcnt, y_train.taxval_pred_lm2)**(1/2)\n",
    "\n",
    "# predict validate\n",
    "y_validate['taxval_pred_lm2'] = lm2.predict(x_validate_degree2)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_validate = mean_squared_error(y_validate.taxvaluedollarcnt, y_validate.taxval_pred_lm2)**(1/2)\n",
    "\n",
    "print(\"RMSE for Polynomial Model, degrees=2\\nTraining/In-Sample: \", rmse_train,\n",
    "      \"\\nValidation/Out-of-Sample: \", rmse_validate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dada2c",
   "metadata": {},
   "source": [
    "This is the best results of all of my models therefor this is the one I will use going forward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744811a5",
   "metadata": {},
   "source": [
    "IMPORTANT FINDINGS FROM EVALUATION:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f7dd0d",
   "metadata": {},
   "source": [
    "- I was able to create 3 models that are training and validating above or around the baseline\n",
    "- My best performing model is my polynomial model validating at an RMSE of 281607.03250049026"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cca5dc9",
   "metadata": {},
   "source": [
    "# Testing best model:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52252c8",
   "metadata": {},
   "source": [
    "Lets test the best model against unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30c48e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make the polynomial features to get a new set of features\n",
    "pf = PolynomialFeatures(degree=2)\n",
    "\n",
    "# fit and transform X_train_scaled\n",
    "x_train_degree2 = pf.fit_transform(x_train)\n",
    "\n",
    "# transform X_validate_scaled & X_test_scaled\n",
    "x_validate_degree2 = pf.transform(x_validate)\n",
    "x_test_degree2 = pf.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e23bb9c-855a-4625-9f34-f439febc8cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE for Polynomial Model, degrees=2\n",
      "Test/Out-of-Sample:  280758.8617654899\n"
     ]
    }
   ],
   "source": [
    "# create the model object\n",
    "lm2 = LinearRegression(normalize=True)\n",
    "\n",
    "# fit the model to our training data. We must specify the column in y_train,\n",
    "# since we have converted it to a dataframe from a series!\n",
    "lm2.fit(x_train_degree2, y_train.taxvaluedollarcnt)\n",
    "\n",
    "# predict test\n",
    "y_test['taxval_pred_lm2'] = lm2.predict(x_test_degree2)\n",
    "\n",
    "# evaluate: rmse\n",
    "rmse_test = mean_squared_error(y_test.taxvaluedollarcnt, y_test.taxval_pred_lm2)**(1/2)\n",
    "\n",
    "print(\"RMSE for Polynomial Model, degrees=2\\nTest/Out-of-Sample: \", rmse_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea0fd93",
   "metadata": {},
   "source": [
    "As you can see We are  testing at an RMSE of 280758.86  which is much better than our baseline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119ed98c",
   "metadata": {},
   "source": [
    "#  Creating Predictions CSV:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa3b0a5",
   "metadata": {},
   "source": [
    "# Conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9789f99",
   "metadata": {},
   "source": [
    "In conclusion I found some important features to look at moving forward as well as made a good start on creating a model that can closely predict house prices. In the future I would like to experiment a little more with my feature engineering and find a way to include more data that can further reduce my errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30c3bca",
   "metadata": {},
   "source": [
    "# Business Reccomendation : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436ebcb3",
   "metadata": {},
   "source": [
    "Since I was a able to close the gap of or errors significantly from the baseline I think that it would be very benificial to allow me more time to continue improving upon my model to help more accurate predict house prices. but for the time being I think that using my model for predicting house prices would help us evaluate houses more accurately."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
